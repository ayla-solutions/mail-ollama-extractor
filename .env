# =========================
# Ollama connection
# =========================
# Your public ACI FQDN:PORT from the model host (already running)
OLLAMA_HOST=http://ollama-mail-statementapi.australiaeast.azurecontainer.io:11434

# Small models you created
CLASSIFIER_MODEL=mail-classifier-small
INVOICE_MODEL=invoice-extractor-small
REQUEST_MODEL=request-summarizer-small

# Make extractor behave like your PowerShell test
OLLAMA_TEMPERATURE=0.2
OLLAMA_NUM_PREDICT=160
OLLAMA_NUM_CTX=1024
OLLAMA_KEEP_ALIVE=30m

# =========================
# Runtime behavior
# =========================
# Hard cap on input size sent to LLM (chars)
EXTRACTOR_MAX_CHARS=12000

# If set, include this prefix in generated ticket numbers (e.g., "CR-")
TICKET_PREFIX=CR-

# Keep responses deterministic for same graph_id (True/False)
TICKET_DETERMINISTIC=True

INVOICE_NUM_PREDICT=400
